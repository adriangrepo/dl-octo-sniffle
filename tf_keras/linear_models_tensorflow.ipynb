{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP's in Tensorflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code based on https://danijar.github.io/structuring-your-tensorflow-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:28:00.746606Z",
     "start_time": "2019-02-08T13:28:00.743661Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import functools\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:28:30.204339Z",
     "start_time": "2019-02-08T13:28:30.199461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf: 1.12.0\n",
      "keras: 2.2.4\n"
     ]
    }
   ],
   "source": [
    "print(f'tf: {tf.__version__}')\n",
    "print(f'keras: {keras.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:34:33.958185Z",
     "start_time": "2019-02-08T13:34:33.954672Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.get_variable_scope().reuse_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:28:31.590853Z",
     "start_time": "2019-02-08T13:28:31.370702Z"
    }
   },
   "outputs": [],
   "source": [
    "# mnist from keras datasets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:28:31.903433Z",
     "start_time": "2019-02-08T13:28:31.892575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_labels = len(np.unique(y_train))\n",
    "n_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:28:32.377575Z",
     "start_time": "2019-02-08T13:28:32.371635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000,), 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:28:32.855936Z",
     "start_time": "2019-02-08T13:28:32.849865Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert to one-hot vector\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:28:33.318617Z",
     "start_time": "2019-02-08T13:28:33.314846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:28:33.816986Z",
     "start_time": "2019-02-08T13:28:33.812408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:28:34.312535Z",
     "start_time": "2019-02-08T13:28:34.308201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = x_train.shape[1]\n",
    "image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:28:34.843104Z",
     "start_time": "2019-02-08T13:28:34.837599Z"
    }
   },
   "outputs": [],
   "source": [
    "# resize - note we have an extra dimension cf linear model\n",
    "x_train = np.reshape(x_train,[-1, image_size, image_size, 1])\n",
    "x_test = np.reshape(x_test,[-1, image_size, image_size, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:28:35.370366Z",
     "start_time": "2019-02-08T13:28:35.365520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:28:35.862035Z",
     "start_time": "2019-02-08T13:28:35.857835Z"
    }
   },
   "outputs": [],
   "source": [
    "image_size_1 = x_train.shape[1]\n",
    "image_size_2 = x_train.shape[2]\n",
    "input_size = image_size_1 * image_size_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:28:36.574412Z",
     "start_time": "2019-02-08T13:28:36.418761Z"
    }
   },
   "outputs": [],
   "source": [
    "# resize \n",
    "x_train = np.reshape(x_train, [-1, input_size])\n",
    "x_test = np.reshape(x_test, [-1, input_size])\n",
    "# limit between 0 & 1\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:28:37.000301Z",
     "start_time": "2019-02-08T13:28:36.994316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:28:37.544636Z",
     "start_time": "2019-02-08T13:28:37.537684Z"
    }
   },
   "outputs": [],
   "source": [
    "def doublewrap(function):\n",
    "    \"\"\"\n",
    "    A decorator decorator, allowing to use the decorator to be used without\n",
    "    parentheses if no arguments are provided. All arguments must be optional.\n",
    "    \"\"\"\n",
    "    @functools.wraps(function)\n",
    "    def decorator(*args, **kwargs):\n",
    "        if len(args) == 1 and len(kwargs) == 0 and callable(args[0]):\n",
    "            return function(args[0])\n",
    "        else:\n",
    "            return lambda wrapee: function(wrapee, *args, **kwargs)\n",
    "    return decorator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:28:38.168889Z",
     "start_time": "2019-02-08T13:28:38.161550Z"
    }
   },
   "outputs": [],
   "source": [
    "@doublewrap\n",
    "def define_scope(function, scope=None, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    A decorator for functions that define TensorFlow operations. The wrapped\n",
    "    function will only be executed once. Subsequent calls to it will directly\n",
    "    return the result so that operations are added to the graph only once.\n",
    "\n",
    "    The operations added by the function live within a tf.variable_scope(). If\n",
    "    this decorator is used with arguments, they will be forwarded to the\n",
    "    variable scope. The scope name defaults to the name of the wrapped\n",
    "    function.\n",
    "    \"\"\"\n",
    "    attribute = '_cache_' + function.__name__\n",
    "    name = scope or function.__name__\n",
    "    @property\n",
    "    @functools.wraps(function)\n",
    "    def decorator(self):\n",
    "        if not hasattr(self, attribute):\n",
    "            with tf.variable_scope(name, *args, **kwargs):\n",
    "                setattr(self, attribute, function(self))\n",
    "        return getattr(self, attribute)\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:34:38.861990Z",
     "start_time": "2019-02-08T13:34:38.851204Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self, image, label):\n",
    "        self.image = image\n",
    "        self.label = label\n",
    "        self.prediction\n",
    "        self.optimize\n",
    "        self.error\n",
    "\n",
    "    @define_scope(initializer=tf.contrib.slim.xavier_initializer())\n",
    "    def prediction(self):\n",
    "        x = self.image\n",
    "        x = tf.contrib.slim.fully_connected(x, 200)\n",
    "        x = tf.contrib.slim.fully_connected(x, 200)\n",
    "        x = tf.contrib.slim.fully_connected(x, 10, tf.nn.softmax)\n",
    "        return x\n",
    "\n",
    "    @define_scope\n",
    "    def optimize(self):\n",
    "        logprob = tf.log(self.prediction + 1e-12)\n",
    "        cross_entropy = -tf.reduce_sum(self.label * logprob)\n",
    "        optimizer = tf.train.RMSPropOptimizer(0.03)\n",
    "        return optimizer.minimize(cross_entropy)\n",
    "\n",
    "    @define_scope\n",
    "    def error(self):\n",
    "        mistakes = tf.not_equal(\n",
    "            tf.argmax(self.label, 1), tf.argmax(self.prediction, 1))\n",
    "        return tf.reduce_mean(tf.cast(mistakes, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:37:58.609125Z",
     "start_time": "2019-02-08T13:37:58.602511Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    #TODO update to use keras mnist\n",
    "    mnist = input_data.read_data_sets('../data/', one_hot=True)\n",
    "    image = tf.placeholder(tf.float32, [None, 784])\n",
    "    label = tf.placeholder(tf.float32, [None, 10])\n",
    "    model = Model(image, label)\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    for _ in range(10):\n",
    "        images, labels = mnist.test.images, mnist.test.labels\n",
    "        error = sess.run(model.error, {image: images, label: labels})\n",
    "        print('Test error {:6.2f}%'.format(100 * error))\n",
    "        for _ in range(60):\n",
    "            images, labels = mnist.train.next_batch(100)\n",
    "            sess.run(model.optimize, {image: images, label: labels})\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:38:04.990865Z",
     "start_time": "2019-02-08T13:37:59.226023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-33-d2421282d054>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/walle/.virtualenvs/tf_keras_py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/walle/.virtualenvs/tf_keras_py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /home/walle/.virtualenvs/tf_keras_py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /home/walle/.virtualenvs/tf_keras_py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/walle/.virtualenvs/tf_keras_py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ../data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ../data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/walle/.virtualenvs/tf_keras_py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Test error  91.79%\n",
      "Test error  27.39%\n",
      "Test error  25.50%\n",
      "Test error  16.53%\n",
      "Test error  11.53%\n",
      "Test error   8.76%\n",
      "Test error  11.44%\n",
      "Test error   7.77%\n",
      "Test error  10.35%\n",
      "Test error   9.05%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
